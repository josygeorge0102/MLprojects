{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits=datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data#values are from0 to 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(digits.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display digit 100\n",
    "plt.imshow(digits.images[1010],cmap=plt.cm.gray_r,interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[10],cmap=plt.cm.gray_r,interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=digits.data\n",
    "y=digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Using SVM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using SVM\n",
    "from sklearn.svm import SVC\n",
    "myclassifier=SVC(kernel='linear',random_state=0)#kernel maps data into higher dimension,finding the hyperplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myclassifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, 2, 0, 0, 8, 7, 6, 6, 3, 6, 9, 7, 4, 7, 4, 3, 2, 6, 7, 3,\n",
       "       4, 7, 1, 0, 7, 4, 8, 3, 4, 0, 5, 5, 5, 1, 2, 9, 0, 0, 0, 8, 2, 3,\n",
       "       7, 0, 1, 7, 1, 3, 8, 4, 2, 9, 6, 0, 4, 5, 4, 4, 7, 9, 9, 5, 0, 3,\n",
       "       7, 4, 9, 1, 7, 0, 9, 3, 0, 2, 7, 8, 1, 1, 9, 3, 3, 2, 2, 3, 8, 2,\n",
       "       4, 6, 9, 5, 8, 4, 7, 3, 7, 2, 5, 6, 5, 6, 1, 0, 6, 4, 8, 1, 5, 6,\n",
       "       8, 8, 8, 6, 4, 0, 2, 7, 5, 0, 8, 5, 8, 4, 7, 0, 5, 9, 0, 1, 8, 4,\n",
       "       7, 9, 6, 1, 2, 7, 1, 3, 5, 3, 5, 2, 7, 4, 9, 2, 0, 0, 9, 2, 8, 4,\n",
       "       0, 9, 7, 0, 1, 4, 1, 8, 0, 7, 9, 1, 9, 7, 2, 7, 7, 0, 5, 3, 4, 0,\n",
       "       5, 2, 3, 0, 3, 0, 1, 9, 5, 4, 8, 2, 6, 0, 9, 7, 8, 8, 7, 3, 0, 9,\n",
       "       5, 3, 6, 3, 7, 9, 0, 5, 7, 6, 5, 3, 1, 0, 4, 3, 1, 0, 5, 3, 7, 3,\n",
       "       2, 3, 5, 0, 7, 4, 5, 3, 0, 0, 5, 7, 5, 2, 4, 2, 9, 3, 3, 0, 7, 3,\n",
       "       1, 3, 1, 7, 4, 7, 4, 5, 2, 1, 1, 4, 7, 1, 7, 9, 2, 5, 2, 5, 0, 9,\n",
       "       2, 0, 7, 6, 5, 4, 5, 1, 4, 1, 8, 0, 7, 4, 7, 1, 3, 4, 9, 5, 0, 3,\n",
       "       0, 5, 4, 3, 6, 1, 4, 3, 8, 5, 2, 7, 4, 6, 4, 8, 3, 0, 1, 5, 7, 7,\n",
       "       1, 3, 4, 8, 8, 5, 2, 2, 1, 7, 8, 3, 9, 1, 4, 4, 2, 5, 5, 0, 8, 9,\n",
       "       1, 0, 8, 1, 4, 0, 6, 9, 9, 7, 1, 4, 5, 0, 0, 2, 4, 3, 3, 4, 1, 7,\n",
       "       6, 6, 8, 3, 6, 6, 2, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=myclassifier.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score #used for balanced datasets\n",
    "print('Accuracy Score',accuracy_score(y_test,pred))#our dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "myclassifier=SVC(kernel='rbf',random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myclassifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, 2, 0, 0, 8, 7, 6, 6, 3, 6, 9, 7, 4, 7, 4, 3, 2, 6, 4, 3,\n",
       "       4, 7, 1, 0, 7, 4, 8, 3, 4, 0, 5, 5, 5, 1, 2, 9, 0, 0, 0, 8, 2, 3,\n",
       "       7, 0, 1, 7, 1, 3, 8, 4, 2, 9, 6, 0, 4, 5, 4, 8, 7, 9, 9, 5, 0, 3,\n",
       "       7, 4, 9, 1, 8, 0, 9, 3, 0, 2, 7, 8, 1, 6, 9, 3, 3, 2, 2, 3, 8, 2,\n",
       "       4, 6, 9, 5, 8, 4, 7, 3, 7, 2, 5, 6, 5, 6, 1, 0, 6, 4, 8, 1, 5, 6,\n",
       "       8, 8, 8, 6, 4, 0, 2, 7, 5, 0, 8, 5, 8, 4, 7, 0, 5, 9, 0, 1, 8, 4,\n",
       "       7, 9, 6, 1, 2, 7, 1, 3, 5, 3, 5, 2, 7, 4, 9, 2, 0, 0, 9, 2, 8, 4,\n",
       "       0, 9, 7, 0, 1, 4, 1, 8, 0, 7, 9, 1, 9, 7, 2, 7, 7, 0, 5, 3, 4, 0,\n",
       "       5, 2, 3, 0, 3, 0, 1, 9, 5, 4, 8, 2, 6, 0, 9, 7, 8, 8, 7, 3, 0, 9,\n",
       "       5, 3, 6, 3, 7, 9, 0, 5, 7, 6, 5, 3, 1, 0, 4, 3, 1, 0, 5, 3, 7, 3,\n",
       "       2, 3, 5, 0, 7, 4, 5, 3, 0, 0, 5, 7, 5, 2, 4, 2, 9, 3, 3, 0, 7, 3,\n",
       "       1, 3, 1, 7, 4, 7, 4, 5, 2, 1, 1, 4, 7, 1, 7, 9, 2, 5, 2, 5, 0, 9,\n",
       "       2, 0, 7, 6, 5, 4, 9, 1, 4, 1, 8, 0, 7, 4, 7, 1, 3, 4, 9, 5, 0, 3,\n",
       "       0, 5, 4, 3, 6, 1, 4, 3, 8, 5, 2, 7, 4, 6, 4, 8, 3, 0, 1, 5, 7, 7,\n",
       "       1, 3, 4, 8, 8, 5, 2, 2, 1, 7, 8, 3, 9, 8, 4, 4, 2, 5, 5, 0, 1, 9,\n",
       "       1, 0, 8, 1, 4, 0, 6, 9, 9, 7, 1, 4, 5, 0, 6, 2, 4, 3, 3, 4, 1, 7,\n",
       "       6, 6, 8, 3, 6, 6, 2, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2=myclassifier.predict(X_test)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score #used for balanced datasets\n",
    "print('Accuracy Score',accuracy_score(y_test,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 34,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0, 31,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 40,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 43,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 37,  0,  0,  0,  1],\n",
       "       [ 1,  1,  0,  0,  0,  0, 23,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 42,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  1, 27,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  1,  0, 27]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 35,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 31,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 40,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 43,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0, 37,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0, 25,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 42,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 29,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1,  0, 28]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(y_test,pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using kernel poly\n",
    "from sklearn.svm import SVC\n",
    "myclassifier=SVC(kernel='poly',random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myclassifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, 2, 0, 0, 8, 7, 6, 6, 3, 6, 9, 7, 4, 7, 4, 3, 2, 6, 7, 3,\n",
       "       4, 7, 1, 0, 7, 4, 8, 3, 4, 0, 5, 5, 5, 1, 2, 9, 0, 0, 0, 8, 2, 3,\n",
       "       7, 0, 1, 7, 1, 3, 8, 4, 2, 9, 6, 0, 4, 5, 4, 4, 7, 9, 9, 5, 0, 3,\n",
       "       7, 4, 9, 1, 8, 0, 9, 3, 0, 2, 7, 8, 1, 1, 9, 3, 3, 2, 2, 3, 8, 2,\n",
       "       4, 6, 9, 5, 8, 4, 7, 3, 7, 2, 5, 6, 5, 6, 1, 0, 6, 4, 8, 1, 5, 6,\n",
       "       8, 8, 8, 6, 4, 0, 2, 7, 5, 0, 8, 5, 8, 4, 7, 0, 5, 9, 0, 1, 8, 4,\n",
       "       7, 9, 6, 1, 2, 7, 1, 3, 5, 3, 5, 2, 7, 4, 9, 2, 0, 0, 9, 2, 8, 4,\n",
       "       0, 9, 7, 0, 1, 4, 1, 8, 0, 7, 9, 1, 9, 7, 2, 7, 7, 0, 5, 3, 4, 0,\n",
       "       5, 2, 3, 0, 3, 0, 1, 9, 5, 4, 8, 2, 6, 0, 9, 7, 8, 8, 7, 3, 0, 9,\n",
       "       5, 3, 6, 3, 7, 9, 0, 5, 7, 6, 5, 3, 1, 0, 4, 3, 1, 0, 5, 3, 7, 3,\n",
       "       2, 3, 5, 0, 7, 4, 5, 3, 0, 0, 5, 7, 5, 2, 4, 2, 9, 3, 3, 0, 7, 3,\n",
       "       1, 3, 1, 7, 4, 7, 4, 5, 2, 1, 1, 4, 7, 1, 7, 9, 2, 5, 2, 5, 0, 9,\n",
       "       2, 0, 7, 6, 5, 4, 5, 1, 4, 1, 8, 0, 7, 4, 7, 1, 3, 4, 9, 5, 0, 3,\n",
       "       0, 5, 4, 3, 6, 1, 4, 3, 8, 5, 2, 7, 4, 6, 4, 8, 3, 0, 1, 5, 7, 7,\n",
       "       1, 3, 4, 8, 8, 5, 2, 2, 1, 7, 8, 3, 9, 8, 4, 4, 2, 5, 5, 0, 1, 9,\n",
       "       1, 0, 8, 1, 4, 0, 6, 9, 9, 7, 1, 4, 9, 0, 0, 2, 4, 3, 3, 4, 1, 7,\n",
       "       6, 6, 8, 3, 6, 6, 2, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3=myclassifier.predict(X_test)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.9805555555555555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "print('Accuracy Score',accuracy_score(y_test,pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
